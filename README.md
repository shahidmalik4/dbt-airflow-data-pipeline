## End-to-End Analytics Engineering Platform  

[![Python](https://img.shields.io/badge/python-3.11-blue?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white)](https://airflow.apache.org/)
[![dbt](https://img.shields.io/badge/dbt-FF694B?style=for-the-badge&logo=dbt&logoColor=white)](https://www.getdbt.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009485?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Metabase](https://img.shields.io/badge/Metabase-EC4A3F?style=for-the-badge&logo=metabase&logoColor=white)](https://www.metabase.com/)

[![License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Release](https://img.shields.io/badge/release-v1.0.0-blue?style=for-the-badge)](https://github.com/yourusername/yourrepo/releases)
[![Build](https://img.shields.io/badge/build-passing-brightgreen?style=for-the-badge)](https://github.com/yourusername/yourrepo/actions)
[![Coverage](https://img.shields.io/badge/coverage-100%25-brightgreen?style=for-the-badge)](https://github.com/yourusername/yourrepo)
[![GitHub Repo Size](https://img.shields.io/github/repo-size/yourusername/yourrepo?style=for-the-badge)](https://github.com/yourusername/yourrepo)



A **production-style analytics engineering project** that demonstrates how raw data moves from ingestion â†’ transformation â†’ orchestration â†’ APIs â†’ BI dashboards using modern data stack tools.

This project is designed to **mirror real-world data platforms** used by Analytics Engineers, Data Engineers, and BI teams.

---

## ğŸ§  Project Overview

This repository implements a **complete analytics workflow**:

1. **Data Ingestion** â€“ Load TPCH-style data into Postgres  
2. **Transformations (dbt)** â€“ Build staging, marts, and analytics models  
3. **Orchestration (Airflow)** â€“ Schedule ingestion and dbt runs  
4. **Serving Layer (FastAPI)** â€“ Expose analytics KPIs via REST APIs  
5. **BI & Dashboards (Metabase)** â€“ Explore data visually  

The result is a **fully containerized analytics platform** you can run locally.

---

## ğŸ§  Skills Demonstrated

- Analytics Engineering best practices
- Data modeling (facts, dimensions, KPIs)
- dbt testing & documentation
- Workflow orchestration with Airflow
- API-driven analytics delivery
- BI enablement with Metabase
- Docker-based local data platforms

---

## ğŸ—ï¸ File Structure
```
â”œâ”€â”€ dags
â”‚Â Â  â””â”€â”€ my_dag.py
â”œâ”€â”€ dbt
â”‚Â Â  â””â”€â”€ dbt_project
â”‚Â Â      â”œâ”€â”€ analyses
â”‚Â Â      â”œâ”€â”€ dbt_project.yml
â”‚Â Â      â”œâ”€â”€ logs
â”‚Â Â      â”‚Â Â  â””â”€â”€ dbt.log
â”‚Â Â      â”œâ”€â”€ macros
â”‚Â Â      â”‚Â Â  â””â”€â”€ generate_schema_name.sql
â”‚Â Â      â”œâ”€â”€ models
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ analytics
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ avg_order_value.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ customer_cohort_retention.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ customer_ltv.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ daily_sales.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ order_fulfillment_efficiency.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ orders_over_time.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ product_profitability.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ regional_sales_performance.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ revenue_by_region.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ schema.yml
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ supplier_performance_metrics.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ top_customers.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ top_products.sql
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ marts
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dims
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dim_customer.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dim_part.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dim_partsupp.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ dim_supplier.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ facts
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ fact_lineitem.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ fact_orders.sql
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ schema.yml
â”‚Â Â      â”‚Â Â  â””â”€â”€ staging
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ schema.yml
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ sources.yml
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_customers.sql
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_lineitems.sql
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_nation.sql
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_orders.sql
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_part.sql
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_partsupp.sql
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ stg_region.sql
â”‚Â Â      â”‚Â Â      â””â”€â”€ stg_supplier.sql
â”‚Â Â      â”œâ”€â”€ profiles.yml
â”‚Â Â      â”œâ”€â”€ README.md
â”‚Â Â      â”œâ”€â”€ seeds
â”‚Â Â      â”œâ”€â”€ snapshots
â”‚Â Â      â””â”€â”€ tests
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ fastapi
â”‚Â Â  â”œâ”€â”€ analytics_api.log
â”‚Â Â  â”œâ”€â”€ app
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ routers
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dbt_metadata.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dims_router.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ facts_router.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ kpis_router.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ schemas
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ analytics.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dbt.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dimensions.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ facts.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ utils
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ db.py
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ logging.py
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â””â”€â”€ requirements.txt
â”œâ”€â”€ include
â”‚Â Â  â”œâ”€â”€ dashboard.png
â”‚Â Â  â””â”€â”€ fastapi.png
â”œâ”€â”€ info.txt
â”œâ”€â”€ ingestion
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ load_faker_data.py
â”‚Â Â  â””â”€â”€ postgres_data_load.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup_project.sh
â”œâ”€â”€ sql-scripts
â”‚Â Â  â”œâ”€â”€ init-airflow.sql
â”‚Â Â  â””â”€â”€ init-warehouse.sql
â”œâ”€â”€ start_services.sh
â””â”€â”€ TPCH
    â”œâ”€â”€ customer.tbl
    â”œâ”€â”€ lineitem.tbl
    â”œâ”€â”€ nation.tbl
    â”œâ”€â”€ orders.tbl
    â”œâ”€â”€ partsupp.tbl
    â”œâ”€â”€ part.tbl
    â”œâ”€â”€ region.tbl
    â””â”€â”€ supplier.tbl

```
---

## ğŸ”§ Tech Stack

| Layer            | Tool |
|------------------|------|
| Database         | PostgreSQL |
| Transformations  | dbt |
| Orchestration    | Apache Airflow |
| API Layer        | FastAPI |
| BI / Dashboards  | Metabase |
| Containerization | Docker & Docker Compose |

---

## ğŸ“Š dbt Features Used
- Staging â†’ Marts â†’ Analytics layers
- Tests & custom tests
- Incremental models
- SCD snapshots
- Documentation generation

---

## â±ï¸ Airflow Orchestration

Airflow orchestrates the entire pipeline:

- Warehouse readiness checks
- Ingestion tasks
- dbt run & dbt test
- Retry handling and logging

Each step is **modular, observable, and production-aligned**.

---

## Getting Started / Setup Instructions

1. **Clone the repository**
```bash
git clone https://github.com/shahidmalik4/dbt-airflow-data-pipeline.git
cd dbt-airflow-data-pipeline
```

2. **Set up the Python environment**
```
python -m venv venv
source venv/bin/activate
.\venv\Scripts\Activate.ps1 (on windows - powershell)
.\venv\Scripts\activate.bat (on windows - command prompt)
```

3. **Make scripts executable (Linux / macOS only)**
```
chmod +x ./setup_project.sh
chmod +x ./start_services.sh
```

4. **Run Services (will pull all docker images, build, and run the containers required for the project)**
```
./setup_project.sh
```

5. **dbt Commands (Inside airflow-webserver Container)**
```
dbt debug
dbt docs generate
```

---

## ğŸŒ Access Services

| Service  | URL                        |
|----------|----------------------------|
| Airflow  | [http://localhost:8080](http://localhost:8080) |
| DBT Docs  | [http://localhost:8081](http://localhost:8081) |
| FastAPI  | [http://localhost:8000/docs](http://localhost:8000/docs) |
| Metabase | [http://localhost:3000](http://localhost:3000) |

---

# FastAPI Swagger UI
![My Image](include/fastapi.png)


# Metabase Dashboard
![My Image](include/dashboard.png)


